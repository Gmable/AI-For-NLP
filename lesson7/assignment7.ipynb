{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7 assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first book——k-近邻算法\n",
    "    + 方法：给定一个训练数据集，我们输入一个实例，可以在训练数据集中找到k个与之最接近的实例，这k个实例属于某一类，则这个输入的实例也归属于这一类中。\n",
    "    + 优点：可直接查表，方便\n",
    "    + 缺点：因为每个特征的情况太多，一一列出的话情况太多，导致表太厚；其次这个表的抽象层次不够，当出现没有见过的情况时，就无法预测了\n",
    "\n",
    "- The second book——决策树算法\n",
    "    + 方法：决策树是一种树形结构，每个叶节点到根节点的路径代表一种类别\n",
    "    + 优点：在每个节点做决策，使得每次决策的范围都在缩小，决策过程清晰明了\n",
    "    + 缺点：当无法做出决策的时候，结构之间影响比较大\n",
    "- The third book——朴素贝叶斯分类\n",
    "- The forth book——神经网络\n",
    "    + 模拟人脑决策过程，输入的[x]首先进行一次运算，得到的结果作为下一层（fun()）的输入（中间可能还包含有激活函数）\n",
    "    + 优点：数据量很多的时候，可以预测的很好，因为考虑了所有特征维度\n",
    "    + 缺点：当没有很多数据的时候，就无法预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 推送广告问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输入：一个人的各种特征（如性别、年龄、职业、工资、居住地等）、发的朋友圈、社会热点等\n",
    "- 输出：推送给这个人的广告（有10种广告，0-9代表每一种广告，输出0-9中的一个数字）\n",
    "\n",
    "神经网络冷启动的解决方法：\n",
    "1. 预采集，如根据用户的注册信息提取特征、或让用户提前选择一些偏好的类别\n",
    "2. 利用用户在其他地方已经沉淀的数据进行冷启动（利用现有的开放数据平台）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习的两种类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. classification——categorical(分类变量，每个数字是一种符号，并没有大小之分)\n",
    "2. regression——numerical(数值变量，有数值上的大小之分)\n",
    "    + regression回归，我们根据训练得到一条线，用来进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何衡量模型（预测）的好不好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分类问题：\n",
    "    1. accuracy——对于给定的测试数据集，分类器正确分类的样本/总样本数\n",
    "    2. precision\n",
    "        + True positive (y=True,yhat=True)\n",
    "        + False positive(y=False, yhat=True)\n",
    "        + False negative (y=True,yhat=False)\n",
    "        + True negatice (y=False, yhat=False)\n",
    "    <img src=\"1.png\" width=\"70%\">\n",
    "    $$precision=\\frac{tp}{tp+fp}$$\n",
    "    3. recall\n",
    "    $$recall=\\frac{tp}{tp+fn}$$\n",
    "    4. AOC/AUC\n",
    "    5. F1_score, F2_score\n",
    "    $$F1=2*(precision*recall)/(precision+recall)$$\n",
    "    6. MSE\n",
    "    7. Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting & underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 根据现有的训练数据求得的一个函数，得到的training ACC\n",
    "    + underfitting(欠拟合)——training ACC很低\n",
    "    + 原因：模型过于简单，无法你和训练数据\n",
    "    + 解决方法：可以通过引入多项式，或者神经网络等复杂模型来解决\n",
    "- 根据现有的训练数据求得的一个函数，得到的training ACC很高，但是测试的时候，testing ACC很低\n",
    "    + overfitting（过拟合）——testing ACC很低\n",
    "    + 原因：模型对于测试集有很差的泛化能力（generalization）\n",
    "        1. 训练集的不完备性（数据量不够）；\n",
    "        2. 数据存在噪音；\n",
    "        3. 模型太过于复杂；\n",
    "        4. 训练集和测试集特征分布不一致；\n",
    "        5. 权值学习迭代次数足够多(Overtraining)，拟合了训练数据中的噪声和训练样例中没有代表性的特征；\n",
    "    + 解决方法：\n",
    "        1. 收集更多数据，或根据某种规律“伪造”更多数据\n",
    "        2. 清洗数据\n",
    "        3. 调小模型复杂度，使其适合自己训练集的数量级（缩小宽度和减小深度）(正则化/dropout)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
